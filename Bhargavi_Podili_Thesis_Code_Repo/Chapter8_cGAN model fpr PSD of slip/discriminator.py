# -*- coding: utf-8 -*-
"""discriminator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mtj99gluNy_mO5tiN-sshBYTd4NaGXAa
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile discriminator.py
# import tensorflow as tf
# from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, LeakyReLU, concatenate, Conv2D, Conv2DTranspose, Layer
# from tensorflow.keras.models import Model
# from tensorflow.keras.saving import register_keras_serializable
# 
# LATENT_DIM = 100
# max_H, max_W = 64, 64  # For discriminator input
# 
# class MinibatchDiscrimination(Layer):
#     def __init__(self, num_kernels=100, kernel_dim=5, **kwargs):
#         super().__init__(**kwargs)
#         self.num_kernels = num_kernels
#         self.kernel_dim = kernel_dim
# 
#     def build(self, input_shape):
#         self.T = self.add_weight(
#             shape=(input_shape[-1], self.num_kernels * self.kernel_dim),
#             initializer='glorot_uniform',
#             trainable=True,
#             name='T'
#         )
# 
#     def call(self, x):
#         M = tf.matmul(x, self.T)
#         M = tf.reshape(M, (-1, self.num_kernels, self.kernel_dim))
#         diffs = tf.expand_dims(M, 3) - tf.expand_dims(tf.transpose(M, [1, 2, 0]), 0)
#         abs_diffs = tf.reduce_sum(tf.abs(diffs), axis=2)
#         minibatch_features = tf.reduce_sum(tf.exp(-abs_diffs), axis=2)
#         return tf.concat([x, minibatch_features], axis=1)
# 
# class SpectralNormalization(tf.keras.layers.Wrapper):
#     def build(self, input_shape):
#         self.layer.build(input_shape)
#         self.w = self.layer.kernel
#         self.u = self.add_weight(
#             shape=(1, self.w.shape[-1]),
#             initializer='random_normal',
#             trainable=False,
#             name='sn_u'
#         )
#         super().build(input_shape)
# 
#     def call(self, inputs):
#         w_reshaped = tf.reshape(self.w, [-1, self.w.shape[-1]])
#         u_hat = self.u
#         v_hat = tf.linalg.l2_normalize(tf.matmul(u_hat, tf.transpose(w_reshaped)))
#         u_hat = tf.linalg.l2_normalize(tf.matmul(v_hat, w_reshaped))
#         sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))
#         self.u.assign(u_hat)
#         self.layer.kernel.assign(self.w / sigma)
#         return self.layer(inputs)
# 
# 
# def build_dynamic_discriminator():
#     psd_input = Input(shape=(64, 64))
#     cond_input = Input(shape=(10,))
#     x = Reshape((64, 64, 1))(psd_input)
# 
#     x = SpectralNormalization(Conv2D(32, kernel_size=4, strides=2, padding='same'))(x)
#     x = LeakyReLU(0.2)(x)
#     x = Dropout(0.3)(x)
# 
#     x = SpectralNormalization(Conv2D(64, kernel_size=4, strides=2, padding='same'))(x)
#     x = LeakyReLU(0.2)(x)
#     x = Dropout(0.3)(x)
# 
#     x = SpectralNormalization(Conv2D(128, kernel_size=4, strides=2, padding='same'))(x)
#     x = LeakyReLU(0.2)(x)
#     x = Flatten()(x)
# 
#     x = MinibatchDiscrimination(num_kernels=100, kernel_dim=5)(x)
#     merged = concatenate([x, cond_input])
# 
#     merged = Dense(128)(merged)
#     merged = LeakyReLU(0.2)(merged)
#     merged = Dropout(0.3)(merged)
# 
#     output = Dense(1)(merged)
#     return Model([psd_input, cond_input], output)
#